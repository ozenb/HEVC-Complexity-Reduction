{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/FCD489C6D489839C/Projeler/STAR/Dataset/CU64Samples_AI_CPIH_768_1536_2880_4928_qp27_Test.dat'\n",
    "val_path = '/mnt/FCD489C6D489839C/Projeler/STAR/Dataset/CU64Samples_AI_CPIH_768_1536_2880_4928_qp27_Valid.dat'\n",
    "model_path = 'cnnv1.h5'\n",
    "\n",
    "QP = 27\n",
    "CU = 64\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "size = os.path.getsize(path)\n",
    "val_size = os.path.getsize(val_path)\n",
    "val_sample = int(val_size / (1+ CU*CU))\n",
    "SAMPLENUMBER = int(size / (1 + CU*CU))\n",
    "restSample = SAMPLENUMBER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, path, sampleNumber, batch_size, cu):\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.sampleNumber = sampleNumber\n",
    "        self.cu = cu\n",
    "        self.mean = 0\n",
    "        \n",
    "        #Initialize label and inputs\n",
    "        self.label1 = np.zeros((self.batch_size,1))\n",
    "        self.label2 = np.zeros((self.batch_size,4))\n",
    "        self.label3 = np.zeros((self.batcg_size,16))\n",
    "        self.input = np.zeros((self.batch_size,64*64))\n",
    "        self.store32 = np.zeros((self.batch_size,4,32*32))\n",
    "        self.qp = np.ones(self.batch_size,1)\n",
    "        self.qp = self.qp.dot(QP)\n",
    "        \n",
    "        if self.cu == 64:\n",
    "            self.down16 = np.zeros((self.batch_size,16*16))\n",
    "        elif self.cu == 32:\n",
    "            self.down32 = np.zeros((self.batch_size,32*32))\n",
    "        \n",
    "    def  __len__(self):\n",
    "        return int(np.floor(self.sampleNumber / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        self.f = open(path,'rb')\n",
    "\n",
    "        #Condition for CU 64x64\n",
    "        if self.cu == 64:\n",
    "            #1 sample is enough for 1 input\n",
    "            offset = (1+ self.cu*self.cu)*index\n",
    "            self.f.seek(offset,0)\n",
    "\n",
    "            #Start Reading Bytes\n",
    "\n",
    "            for self.i in range(self.batch_size):\n",
    "                #Label\n",
    "                self.label1[self.i,0] = self.f.read(1)[0]\n",
    "                #Input\n",
    "                self.tmp = self.f.read(self.cu * self.cu)\n",
    "\n",
    "                for self.k in range(self.cu * self.cu):\n",
    "                    #Assign input and decode\n",
    "                    self.input[self.i, self.k] = self.tmp[self.k]\n",
    "                #Preprocessing can be done here!\n",
    "\n",
    "                #Mean Removal\n",
    "                self.mean = np.mean(self.input[self.i,:])\n",
    "                self.input[self.i,:] = self.input[self.i,:] - self.mean\n",
    "\n",
    "                #Downsampling 64x64 -> 16x16\n",
    "                self.down16[self.i,:] = self.input[self.i,::4,::4]\n",
    "            #Batch size end\n",
    "\n",
    "            self.down16 = self.down16.reshape((self.batch_size,16,16))\n",
    "            self.f.close()\n",
    "\n",
    "            return np.array[self.down16, None, None, self.qp], [self.label1 None, None]\n",
    "\n",
    "        elif self.cu == 32:\n",
    "            # 4 sample is needed for 1 input -> 2x2 32x32 sample\n",
    "            self.input = self.input.reshape((self.batch_size,64,64))\n",
    "            offset = (1+ 32*32)*index\n",
    "            self.f.seek(offset,0)\n",
    "\n",
    "            #Start Reading Bytes\n",
    "            self.counter = 0\n",
    "\n",
    "            for self.i in range(self.batch_size):\n",
    "                for self.counter in range(4):\n",
    "                    #Label\n",
    "                    self.label2[self.i,self.counter] = self.f.read(1)[0]\n",
    "                    #input\n",
    "                    self.tmp = self.f.read(32*32)\n",
    "                    for self.k in range(32*32):\n",
    "                        #Assign input and decode\n",
    "                        self.store32[self.i,self.counter,self.k]  = self.tmp[self.k]\n",
    "                    #Preprocessing can be done here!\n",
    "\n",
    "                    #Mean removal\n",
    "\n",
    "                    self.mean = np.mean(self.store32[self.i,self.counter,:])\n",
    "                    self.store32[self.i,self.counter,:] = self.store32[self.i,self.counter,:] - self.mean\n",
    "                #4 samples are obtained\n",
    "                #Concat 4 samples\n",
    "                self.input[self.i,:] =np.vstack(( np.hstack((self.store32[self.i,0,:].reshape((self.batch_size,32,32)),self.store32[self.i,1,:].reshape((self.batch_size,32,32)))), np.hstack((self.store32[self.i,2,:].reshape((self.batch_size,32,32)), self.store32[self.i,3,:].reshape((self.batch_size,32,32)))) ))\n",
    "            #Batching is done!\n",
    "\n",
    "\n",
    "            #Downsampling\n",
    "            self.down32 = self.input[:,::2,::2]\n",
    "\n",
    "            return np.array[None, self.down32, None, self.qp], [None, self.label2, None]\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(path,SAMPLENUMBER, BATCH_SIZE, CU)\n",
    "val_generator = DataGenerator(val_path, val_sample, BATCH_SIZE, CU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Compile CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse = keras.losses.mean_squared_error\n",
    "\n",
    "if CU == 64:\n",
    "    model.compile(loss=[loss_mse, None, None], optimizer = 'adam', metrics=['accuracy'],loss_weights=[1., None, None])\n",
    "elif CU == 32:\n",
    "    model.compile(loss=[None, loss_mse, None], optimizer = 'adam', metrics=['accuracy'], loss_weights=[None, 1., None])\n",
    "elif CU == 16:\n",
    "    model.compile(loss = [None, None, loss_mse], optimizer = 'adam', metrics=['accuracy'], loss_weights=[None, None, 1.])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
