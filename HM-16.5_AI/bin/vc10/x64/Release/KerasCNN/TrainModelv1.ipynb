{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/FCD489C6D489839C/Projeler/STAR/Dataset/CU64Samples_AI_CPIH_768_1536_2880_4928_qp27_Train.dat'\n",
    "val_path = '/mnt/FCD489C6D489839C/Projeler/STAR/Dataset/CU64Samples_AI_CPIH_768_1536_2880_4928_qp27_Valid.dat'\n",
    "model_path = 'cnnv1.h5'\n",
    "\n",
    "QP = 27\n",
    "CU = 64\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "size = os.path.getsize(path)\n",
    "val_size = os.path.getsize(val_path)\n",
    "val_sample = int(val_size / (1+ CU*CU))\n",
    "SAMPLENUMBER = int(size / (1 + CU*CU))\n",
    "restSample = SAMPLENUMBER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, path, sampleNumber, batch_size, cu):\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.sampleNumber = sampleNumber\n",
    "        self.cu = cu\n",
    "        self.mean = 0\n",
    "        \n",
    "        #Initialize label and inputs\n",
    "        self.label1 = np.zeros((self.batch_size,1))\n",
    "        self.label2 = np.zeros((self.batch_size,4))\n",
    "        self.label3 = np.zeros((self.batch_size,16))\n",
    "        self.input = np.zeros((self.batch_size,64*64))\n",
    "        self.store32 = np.zeros((self.batch_size,4,32*32))\n",
    "        self.qp = np.ones((self.batch_size,1))\n",
    "        self.qp = self.qp.dot(QP)\n",
    "        \n",
    "        if self.cu == 64:\n",
    "            self.down16 = np.zeros((self.batch_size,16*16))\n",
    "        elif self.cu == 32:\n",
    "            self.down32 = np.zeros((self.batch_size,32*32))\n",
    "        \n",
    "    def  __len__(self):\n",
    "        return int(np.floor(self.sampleNumber / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        self.f = open(path,'rb')\n",
    "        self.down16 = self.down16.reshape((self.batch_size,16*16))\n",
    "        #Condition for CU 64x64\n",
    "        if self.cu == 64:\n",
    "            #1 sample is enough for 1 input\n",
    "            offset = (1+ self.cu*self.cu)*index\n",
    "            self.f.seek(offset,0)\n",
    "\n",
    "            #Start Reading Bytes\n",
    "\n",
    "            for self.i in range(self.batch_size):\n",
    "                #Label\n",
    "                self.label1[self.i,0] = self.f.read(1)[0]\n",
    "                #Input\n",
    "                self.tmp = self.f.read(self.cu * self.cu)\n",
    "\n",
    "                for self.k in range(self.cu * self.cu):\n",
    "                    #Assign input and decode\n",
    "                    self.input[self.i, self.k] = self.tmp[self.k]\n",
    "                #Preprocessing can be done here!\n",
    "\n",
    "                #Mean Removal\n",
    "                self.mean = np.mean(self.input[self.i,:])\n",
    "                self.input[self.i,:] = self.input[self.i,:] - self.mean\n",
    "\n",
    "                #Downsampling 64x64 -> 16x16\n",
    "                self.down16[self.i,:] = self.input[self.i,::16]\n",
    "            #Batch size end\n",
    "\n",
    "            self.down16 = self.down16.reshape((self.batch_size,16,16,1))\n",
    "            self.f.close()\n",
    "\n",
    "            return [self.down16, np.zeros((self.batch_size,32,32,1)), np.zeros((self.batch_size,64,64,1)), self.qp], [self.label1, np.zeros((self.batch_size,4)), np.zeros((self.batch_size,16))]\n",
    "\n",
    "        elif self.cu == 32:\n",
    "            # 4 sample is needed for 1 input -> 2x2 32x32 sample\n",
    "            self.input = self.input.reshape((self.batch_size,64,64))\n",
    "            offset = (1+ 32*32)*index\n",
    "            self.f.seek(offset,0)\n",
    "\n",
    "            #Start Reading Bytes\n",
    "            self.counter = 0\n",
    "\n",
    "            for self.i in range(self.batch_size):\n",
    "                for self.counter in range(4):\n",
    "                    #Label\n",
    "                    self.label2[self.i,self.counter] = self.f.read(1)[0]\n",
    "                    #input\n",
    "                    self.tmp = self.f.read(32*32)\n",
    "                    for self.k in range(32*32):\n",
    "                        #Assign input and decode\n",
    "                        self.store32[self.i,self.counter,self.k]  = self.tmp[self.k]\n",
    "                    #Preprocessing can be done here!\n",
    "\n",
    "                    #Mean removal\n",
    "\n",
    "                    self.mean = np.mean(self.store32[self.i,self.counter,:])\n",
    "                    self.store32[self.i,self.counter,:] = self.store32[self.i,self.counter,:] - self.mean\n",
    "                #4 samples are obtained\n",
    "                #Concat 4 samples\n",
    "                self.input[self.i,:] =np.vstack(( np.hstack((self.store32[self.i,0,:].reshape((self.batch_size,32,32)),self.store32[self.i,1,:].reshape((self.batch_size,32,32)))), np.hstack((self.store32[self.i,2,:].reshape((self.batch_size,32,32)), self.store32[self.i,3,:].reshape((self.batch_size,32,32)) )) ))\n",
    "            #Batching is done!\n",
    "\n",
    "\n",
    "            #Downsampling\n",
    "            self.down32 = self.input[:,::2]\n",
    "\n",
    "            return [np.zeros((self.batch_size,16,16)), self.down32, np.zeros((self.batch_size,64,64)), self.qp], [None, self.label2, None]\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(path,SAMPLENUMBER, BATCH_SIZE, CU)\n",
    "val_generator = DataGenerator(val_path, val_sample, BATCH_SIZE, CU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Compile CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d3dx9/.local/lib/python3.6/site-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse = keras.losses.mean_squared_error\n",
    "\n",
    "if CU == 64:\n",
    "    model.compile(loss=[loss_mse, loss_mse, loss_mse], optimizer = 'adam', metrics=['accuracy'],loss_weights=[1., 0, 0])\n",
    "elif CU == 32:\n",
    "    model.compile(loss=[None, loss_mse, None], optimizer = 'adam', metrics=['accuracy'], loss_weights=[None, 1., None])\n",
    "elif CU == 16:\n",
    "    model.compile(loss = [None, None, loss_mse], optimizer = 'adam', metrics=['accuracy'], loss_weights=[None, None, 1.])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38230/38230 [==============================] - 1486s 39ms/step - loss: 0.0303 - dense_7_loss: 0.0303 - dense_8_loss: 0.8217 - dense_9_loss: 0.4207 - dense_7_acc: 0.9626 - dense_8_acc: 0.3848 - dense_9_acc: 0.0083 - val_loss: 0.0232 - val_dense_7_loss: 0.0232 - val_dense_8_loss: 0.7854 - val_dense_9_loss: 0.4288 - val_dense_7_acc: 0.9741 - val_dense_8_acc: 0.5232 - val_dense_9_acc: 0.0191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32fa72ada0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(test_generator,epochs=1,verbose=1,validation_data= val_generator,workers = 4, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('net_cnnv1_CU64_trained_epoch1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
